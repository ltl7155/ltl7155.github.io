---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
redirect_from: 
  - /pubs
  - /pubs.html
  - /publications
  - /publications.html
---

You can also find my articles on <u><a href="{{author.googlescholar}}">my Google Scholar profile</a>.</u> <i>(* for co-first author, # for corresponding author)</i>

---

<p>
<a class="media" href="https://ltl7155.github.io/404.html" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; <font color="blue">Tianlin Li</font>, Qian Liu, Tianyu Pang, Chao Du, Qing Guo, Yang Liu, Min Lin. Purifying Large Language Models by Ensembling a Small Language Model, Preprint.
</p>

<p>
<a class="media" href="https://ltl7155.github.io/404.html" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; Yihao Huang, Yue Cao, <font color="blue">Tianlin Li#</font>, Felix Juefei-Xu, Di Lin, Ivor W Tsang, Yang
Liu, Qing Guo#. On the robustness of segment anything, Preprint.
</p>

<p>
<a class="media" href="https://ltl7155.github.io/404.html" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; Xiaoyu Zhang, <font color="blue">Tianlin Li</font>, Cen Zhang, Yihao Huang, Xiaojun Jia, Xiaofei Xie,
Yang Liu, Chao Shen. A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection, Preprint.
</p>

<p>
<a class="media" href="https://openreview.net/forum?id=uOwJEPtyOF" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; <font color="blue">Tianlin Li*</font>, Xiaoyu Zhang*, Chao Du, Tianyu Pang, Qian Liu, Qing Guo, Chao
Shen, Yang Liu. Your Large Language Model is Secretly a Fairness Proponent and You
Should Prompt it Like One, Preprint.
</p>

<p>
<a class="media" href="https://ltl7155.github.io/404.html" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; Zhiming Li, Yanzhou Li, <font color="blue">Tianlin Li#</font>, Mengnan Du, Bozhi Wu, Yushi Cao, Xi-
aofei Xie, Yi Li, Yang Liu. Unveiling Project-Specific Bias in Neural Code Models, LREC-Coling 2024.
</p>

<p>
<a class="media" href="https://ltl7155.github.io/404.html" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; Yanzhou Li, <font color="blue">Tianlin Li#</font>, Kangjie Chen#, Jian Zhang, Shangqing Liu, Wenhan
Wang, Tianwei Zhang, Yang Liu. BadEdit: Backdooring Large Language Models by Model Editing, ICLR 2024.
</p>

<p>
<a class="media" href="https://ltl7155.github.io/files/pubs/2023-ieeesp-rengar.pdf" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; Yue Cao, <font color="blue">Tianlin Li*</font>, Xiaofeng Cao, Ivor Tsang, Yang Liu, Qing Guo. IRAD: Implicit Representation-driven Image Resampling against Adversarial Attacks, ICLR 2024.
</p>

<p>
<a class="media" href="https://www.usenix.org/conference/usenixsecurity23/presentation/zhang-cen" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; Zixin Yin*, Jiakai Wang*, Yisong Xiao, Hanqing Zhao, <font color="blue">Tianlin Li</font>, Wenbo Zhou, Aishan Liu, and Xianglong Liu. Improving Deepfake Detection Generalization by Invariant Risk Minimization, TMM 2024.
</p>

<p>
<a class="media" href="https://ltl7155.github.io/files/pubs/2022-issta-equafl.pdf" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; Ming Hu, Yue Cao, Anran Li, Zhiming Li, Chengwei Liu, <font color="blue">Tianlin Li</font>, Mingsong Chen, Yang Liu. FedMut: Generalized Federated Learning via Stochastic Mutation, AAAI 2024 <font color="red">oral</font>.
</p>

<p>
<a class="media" href="https://ltl7155.github.io/files/pubs/2021-ccs-ecmo.pdf" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; Yihao Huang, Felix Juefei-Xu, Qing Guo, Jie Zhang, Yutong Wu, Hu Ming, <font color="blue">Tianlin Li</font>, Geguang Pu, Yang Liu. Personalization as a Shortcut for Few-Shot Backdoor Attack against Text-to-Image Diffusion Models, AAAI 2024.
</p>

<p>
<a class="media" href="https://www.usenix.org/conference/usenixsecurity21/presentation/zhang-cen" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; Jian Zhang, Shangqing Liu, Xu Wang, <font color="blue">Tianlin Li</font>, Yang Liu. Learning to Locate and Describe Vulnerabilities, ASE 2023.
</p>

<p>
<a class="media" href="https://ltl7155.github.io/files/pubs/2021-ase-firmguide.pdf" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; <font color="blue">Tianlin Li*</font>, Yue Cao*, Jian Zhang, Shiqian Zhao, Yihao Huang, Aishan Liu, Qing Guo, Yang Liu. RUNNER: Responsible UNfair NEuron Repair for Enhancing Deep Neural Network Fairness, ICSE 2024 <font color="red">oral</font>.
</p>

<p>
<a class="media" href="https://ltl7155.github.io/404.html" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; <font color="blue">Tianlin Li</font>, Xiaofei Xie, Jian Wang, Qing Guo, Aishan Liu, Lei Ma, Yang Liu. Faire: Repairing Fairness of Neural Networks via Neuron Condition Synthesis, TOSEM 2023.
</p>

<p>
<a class="media" href="https://ltl7155.github.io/404.html" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; <font color="blue">Tianlin Li</font>, Qing Guo, Aishan Liu, Mengnan Du, Zhiming Li, Yang Liu. FAIRER: FAIRNESS AS DECISION RATIONALE ALIGNMENT, ICML 2023.
</p>

<p>
<a class="media" href="https://ltl7155.github.io/404.html" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; <font color="blue">Tianlin Li</font>, Zhiming Li, Anran Li, Mengnan Du, Aishan Liu, Qing Guo, Guozhu
Meng, Yang Liu. Fairness via Group Contribution Matching, IJCAI 2023 <font color="red">oral</font>.
</p>

<p>
<a class="media" href="https://ltl7155.github.io/404.html" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; Yisong Xiao, Aishan Liu, <font color="blue">Tianlin Li</font>,Xianglong Liu. Latent Imitator: Generating Natural Individual Discriminatory, ISSTA 2023.
</p>

<p>
<a class="media" href="https://ltl7155.github.io/404.html" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp;  <font color="blue">Tianlin Li*</font>, Aishan Liu*, Xianglong Liu, Yitao Xu, Chongzhi Zhang, Xiaofei Xie. Understanding adversarial robustness via critical attacking route, Information Science 2020.
</p>

<p>
<a class="media" href="https://ltl7155.github.io/404.html" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; Xiaofei Xie*, <font color="blue">Tianlin Li*</font>, Jian Wang, Lei Ma, Qing Guo, Felix Juefei-Xu, Yang Liu. Decision Logic of Deep Neural Networks, TOSEM 2021.

</p>

<p>
<a class="media" href="https://ltl7155.github.io/404.html" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; Ruofan Liang*, <font color="blue">Tianlin Li*</font>, Longfei Li, Jing Wang, Quanshi Zhang. Knowledge consistency between neural networks, ICLR 2020.
</p>

---
