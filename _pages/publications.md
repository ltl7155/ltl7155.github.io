---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
redirect_from: 
  - /pubs
  - /pubs.html
  - /publications
  - /publications.html
---

You can also find my articles on <u><a href="https://scholar.google.com/citations?user=XB6CydwAAAAJ&hl=en">my Google Scholar profile</a>.</u> <i>(* for co-first author, # for corresponding author)</i>

---

### AI Security: 
---

<p>
<a class="media" href="https://ltl7155.github.io/404.html" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; <b>[Preprint]</b> <font color="blue">Tianlin Li</font>, Qian Liu, Tianyu Pang, Chao Du, Qing Guo, Yang Liu, Min Lin. Purifying Large Language Models by Ensembling a Small Language Model.
</p>


<p>
<a class="media" href="https://ltl7155.github.io/404.html" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; <b>[Preprint]</b> Yihao Huang, Yue Cao, <font color="blue">Tianlin Li#</font>, Felix Juefei-Xu, Di Lin, Ivor W Tsang, Yang Liu, Qing Guo#. On the robustness of segment anything.
</p>

<p>
<a class="media" href="https://ltl7155.github.io/404.html" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; <b>[TIFS 2025]</b> Aishan Liu, Yuguang Zhou, Xianglong Liu, Tianyuan Zhang, Siyuan Liang, Jiakai Wang, Yanjun Pu, <font color="blue">Tianlin Li</font>, Junqi Zhang, Wenbo Zhou, Qing Guo, Dacheng Tao. Compromising Embodied Agents with Contextual Backdoor Attacks.
</p>

<p>
<a class="media" href="https://ltl7155.github.io/404.html" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; <b>[TOSEM 2025]</b> Xiaoyu Zhang, Cen Zhang, <font color="blue">Tianlin Li</font>, Yihao Huang, Xiaojun Jia, Xiaofei Xie,
Yang Liu, Chao Shen. A Mutation-Based Method for Multi-Modal Jailbreaking Attack Detection.
</p>

<p>
<a class="media" href="https://ltl7155.github.io/404.html" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; <b>[USENIX Security 2025]</b> Jiachen Zhou, Mingsi Wang, <font color="blue">Tianlin Li</font>, Guozhu Meng, Kai Chen, Dormant: Defending against Pose-driven Human Image Animation.
</p>

<p>
<a class="media" href="https://ltl7155.github.io/404.html" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; <b>[ICSE 2025]</b> Shide Zhou, <font color="blue">Tianlin Li#</font>, Kailong Wang#, Yihao Huang, Ling Shi, Yang Liu, Haoyu Wang, Understanding the Effectiveness of Coverage Criteria for Large Language Models: A Special Angle from Jailbreak Attacks.
</p>


<p>
<a class="media" href="https://ltl7155.github.io/404.html" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; <b>[ICSE 2025]</b> Yisong Xiao, Aishan Liu, Xinwei Zhang, Tianyuan Zhang, <font color="blue">Tianlin Li</font>, Siyuan Liang, Xianglong Liu, Yang Liu, Dacheng Tao,  BDefects4NN: A Backdoor Defect Database for Controlled Localization Studies in Neural Networks.
</p>

<p>
<a class="media" href="https://ltl7155.github.io/404.html" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; <b>[AAAI 2025</b> <font color="red">oral</font><b>]</b> Yihao Huang, Le Liang, <font color="blue">Tianlin Li</font>, Xiaojun Jia, Run Wang, Weikai Miao, Geguang Pu, Yang Liu,  Perception-guided jailbreak against text-to-image models.
</p>

<p>
<a class="media" href="https://ltl7155.github.io/404.html" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; <b>[NeurIPS 2024]</b> Yanxin Yang, Chentao Jia, Dengke Yan, Ming Hu, <font color="blue">Tianlin Li</font>, Xiaofei Xie, Xian Wei, and Mingsong Chen,  SampDetox: Black-box Backdoor Defense via Perturbation-based Sample Detoxification.
</p>

<p>
<a class="media" href="https://ltl7155.github.io/404.html" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; <b>[ICLR 2024]</b> Yanzhou Li, <font color="blue">Tianlin Li#</font>, Kangjie Chen#, Jian Zhang, Shangqing Liu, Wenhan
Wang, Tianwei Zhang, Yang Liu. BadEdit: Backdooring Large Language Models by Model Editing.
</p>

<p>
<a class="media" href="https://ltl7155.github.io/files/pubs/2023-ieeesp-rengar.pdf" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; <b>[ICLR 2024]</b> Yue Cao, <font color="blue">Tianlin Li</font>, Xiaofeng Cao, Ivor Tsang, Yang Liu, Qing Guo. IRAD: Implicit Representation-driven Image Resampling against Adversarial Attacks.
</p>

<p>
<a class="media" href="https://www.usenix.org/conference/usenixsecurity23/presentation/zhang-cen" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp;  <b>[TMM 2024]</b> Zixin Yin, Jiakai Wang, Yisong Xiao, Hanqing Zhao, <font color="blue">Tianlin Li</font>, Wenbo Zhou, Aishan Liu, and Xianglong Liu. Improving Deepfake Detection Generalization by Invariant Risk Minimization.
</p>

<p>
<a class="media" href="https://ltl7155.github.io/files/pubs/2021-ccs-ecmo.pdf" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; <b>[AAAI 2024]</b> Yihao Huang, Felix Juefei-Xu, Qing Guo, Jie Zhang, Yutong Wu, Hu Ming, <font color="blue">Tianlin Li</font>, Geguang Pu, Yang Liu. Personalization as a Shortcut for Few-Shot Backdoor Attack against Text-to-Image Diffusion Models.
</p>


<p>
<a class="media" href="https://ltl7155.github.io/404.html" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; <b>[TOSEM 2021]</b> Xiaofei Xie*, <font color="blue">Tianlin Li*</font>, Jian Wang, Lei Ma, Qing Guo, Felix Juefei-Xu, Yang Liu. Npc: Neuron path coverage via characterizing decision logic of deep neural networks.
</p>


<p>
<a class="media" href="https://ltl7155.github.io/404.html" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; <b>[TIP 2020]</b> Chongzhi Zhang, Aishan Liu, Xianglong Liu, Yitao Xu, Hang Yu, Yuqing Ma, <font color="blue">Tianlin Li</font>. Interpreting and improving adversarial robustness of deep neural networks with neuron sensitivity.
</p>

<p>
<a class="media" href="https://ltl7155.github.io/404.html" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; <b>[Information Science 2020]</b> <font color="blue">Tianlin Li*</font>, Aishan Liu*, Xianglong Liu, Yitao Xu, Chongzhi Zhang, Xiaofei Xie. Understanding adversarial robustness via critical attacking route.
</p>



### AI Fairness: 
---


<p>
<a class="media" href="https://openreview.net/forum?id=uOwJEPtyOF" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; <b>[Preprint]</b> <font color="blue">Tianlin Li*</font>, Xiaoyu Zhang*, Chao Du, Tianyu Pang, Qian Liu, Qing Guo, Chao Shen, Yang Liu. Your Large Language Model is Secretly a Fairness Proponent and You Should Prompt it Like One.
</p>

<p>
<a class="media" href="https://openreview.net/forum?id=uOwJEPtyOF" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; <b>[FSE 2025]</b> Zhenpeng Chen, Xinyue Li, Jie M. Zhang, Weisong Sun, Ying Xiao, <font color="blue">Tianlin Li</font>,, Yiling Lou, Yang Liu.  Software Fairness Dilemma: Is Bias Mitigation a Zero-Sum Game?
</p>

<p>
<a class="media" href="https://ltl7155.github.io/404.html" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; <b>[ICSE 2025]</b> Lili Quan, <font color="blue">Tianlin Li#</font>, Xiaofei Xie, Zhenpeng Chen, Xiaofei Xie, Sen Chen, Lingxiao Jiang, Xiaohong Li#, Dissecting Global Search: A Simple Yet Effective Method to Boost Individual Discrimination Testing and Repair.
</p>

<p>
<a class="media" href="https://ltl7155.github.io/files/pubs/2021-ase-firmguide.pdf" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp;  <b>[ICSE 2024]</b> <font color="blue">Tianlin Li*</font>, Yue Cao*, Jian Zhang, Shiqian Zhao, Yihao Huang, Aishan Liu, Qing Guo, Yang Liu. RUNNER: Responsible UNfair NEuron Repair for Enhancing Deep Neural Network Fairness.
</p>

<p>
<a class="media" href="https://ltl7155.github.io/404.html" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; <b>[TOSEM 2023]</b> <font color="blue">Tianlin Li</font>, Xiaofei Xie, Jian Wang, Qing Guo, Aishan Liu, Lei Ma, Yang Liu. Faire: Repairing Fairness of Neural Networks via Neuron Condition Synthesis.
</p>

<p>
<a class="media" href="https://ltl7155.github.io/404.html" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; <b>[ICML 2023]</b> <font color="blue">Tianlin Li</font>, Qing Guo, Aishan Liu, Mengnan Du, Zhiming Li, Yang Liu. FAIRER: FAIRNESS AS DECISION RATIONALE ALIGNMENT.
</p>

<p>
<a class="media" href="https://ltl7155.github.io/404.html" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; <b>[IJCAI 2023]</b> <font color="blue">Tianlin Li</font>, Zhiming Li, Anran Li, Mengnan Du, Aishan Liu, Qing Guo, Guozhu Meng, Yang Liu. Fairness via Group Contribution Matching.
</p>

<p>
<a class="media" href="https://ltl7155.github.io/404.html" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; <b>[ISSTA 2023]</b> Yisong Xiao, Aishan Liu, <font color="blue">Tianlin Li</font>, Xianglong Liu. Latent Imitator: Generating Natural Individual Discriminatory.
</p>





### Trustworthy Code Intelligence: 
---



<p>
<a class="media" href="https://ltl7155.github.io/404.html" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; <b>[TOSEM 2025]</b> Chong Wang, Jian Zhang, Yebo Feng, <font color="blue">Tianlin Li</font>, Weisong Sun, Yang Liu, Xin Peng,  Teaching Code LLMs to Use Autocompletion Tools in Repository-Level Code Generation.
</p>

<p>
<a class="media" href="https://ltl7155.github.io/404.html" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; <b>[ICSE NEIR 2025]</b> Chong Wang, Zhenpeng Chen, <font color="blue">Tianlin Li</font>, Yilun Zhao, Yang Liu,  Towards Trustworthy LLMs for Code: A Data-Centric Synergistic Auditing Framework.
</p>

<p>
<a class="media" href="https://ltl7155.github.io/404.html" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; <b>[ASE 2024]</b> Jian Zhang, Chong Wang, Anran Li, Wenhan Wang, <font color="blue">Tianlin Li</font>, Yang Liu, VulAdvisor: Natural Language Suggestion Generation for Software Vulnerability Repair.
</p>


<p>
<a class="media" href="https://ltl7155.github.io/404.html" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; <b>[LREC-Coling 2024]</b> Zhiming Li, Yanzhou Li, <font color="blue">Tianlin Li#</font>, Mengnan Du, Bozhi Wu, Yushi Cao, Xiaofei Xie, Yi Li, Yang Liu. Unveiling Project-Specific Bias in Neural Code Models.
</p>


<p>
<a class="media" href="https://www.usenix.org/conference/usenixsecurity21/presentation/zhang-cen" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; <b>[ASE 2023]</b> Jian Zhang, Shangqing Liu, Xu Wang, <font color="blue">Tianlin Li</font>, Yang Liu. Learning to Locate and Describe Vulnerabilities.
</p>


### Interpretability and Its Applications:
---

<p>
<a class="media" href="https://ltl7155.github.io/404.html" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; <b>[TOSEM 2025]</b> Shide Zhou,<font color="blue">Tianlin Li#</font>, Yihao Huang, Ling Shi, Kailong Wang#, Yang Liu, Haoyu Wang. NeuSemSlice: Towards Effective DNN Model Maintenance via Neuron-level Semantic Slicing.
</p>


<p>
<a class="media" href="https://ltl7155.github.io/404.html" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; <b>[ICLR 2025]</b> Xiaoyu Zhang, Juan Zhai, Shiqing Ma, Chao Shen,<font color="blue">Tianlin Li</font>, Weipeng Jiang, Yang Liu. Speculative Coreset Selection for Task-Specific Fine-tuning.
</p>

<p>
<a class="media" href="https://ltl7155.github.io/404.html" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; <b>[EMSOFT 2024, TCAD]</b> Zeke Xia, Ming Hu, Dengke Yan, Xiaofei Xie, <font color="blue">Tianlin Li</font>, Anran Li, Junlong Zhou, and Mingsong Chen.  CaBaFL: Asynchronous Federated Learning via Hierarchical Cache and Feature Balance.
</p>

<p>
<a class="media" href="https://ltl7155.github.io/404.html" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; <b>[ICML 2024]</b>  Zhiming Li, Yushi Cao, Yan Zheng#, Xu Liu, Bozhi Wu, <font color="blue">Tianlin Li#</font>, Xiufeng Xu, Junzhe Jiang, Yon Shin Teo, Shang-Wei Lin, Yang Liu. Improving Neural Logic Machines via Failure Reflection.
</p>

<p>
<a class="media" href="https://ltl7155.github.io/files/pubs/2022-issta-equafl.pdf" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp; <b>[AAAI 2024</b> <font color="red">oral</font><b>]</b>  Ming Hu, Yue Cao, Anran Li, Zhiming Li, Chengwei Liu, <font color="blue">Tianlin Li</font>, Mingsong Chen, Yang Liu. FedMut: Generalized Federated Learning via Stochastic Mutation.
</p>

<p>
<a class="media" href="https://ltl7155.github.io/404.html" target="_blank"><img src="https://ltl7155.github.io/images/pdf.png"></a>&nbsp;<b>[ICLR 2020]</b>  Ruofan Liang*, <font color="blue">Tianlin Li*</font>, Longfei Li, Jing Wang, Quanshi Zhang. Knowledge consistency between neural networks.
</p>



---
