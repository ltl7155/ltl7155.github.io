---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

---

I'm a research fellow at the CCDS, Nanyang Technological University, under the supervision of [Prof. Liu Yang](https://personal.ntu.edu.sg/yangliu/). 
I have been awarded the AISG PhD Fellowship and the DAAD AInet Fellowship, along with third place in the AISG Trusted Media Challenge, receiving a cash prize of 25,000 SGD. I feel fortunate to have the opportunity to work with Tianyu Pang, Chao Du, Qian Liu, and Min Lin at Sea AI Lab.

My research focuses on developing trustworthy AI software, a direction at the intersection of AI and Software Engineering. 
My research on AI software trustworthiness spans three levels: AI infrastructure, AI models, and AI agents, across applications such as chatbots, code generation, and medical scenarios.
- AI Security: [[ICML 2025]](https://arxiv.org/abs/2412.12722), [[TIFS 2025]](https://arxiv.org/abs/2408.02882), [[TOSEM 2025]](https://arxiv.org/abs/2312.10766), [[USENIX Security 2025]](https://arxiv.org/abs/2409.14424), [[ICSE 2025]](https://arxiv.org/abs/2408.15207), [[ICSE 2025]](https://arxiv.org/abs/2412.00746), [[AAAI 2025]](https://arxiv.org/abs/2408.10848), [[NeurIPS 2024]](https://ink.library.smu.edu.sg/sis_research/9812/), [[ICLR 2024]](https://arxiv.org/abs/2403.13355), [[ICLR 2024]](https://arxiv.org/abs/2310.11890), [[TMM 2024]](https://ieeexplore.ieee.org/document/10409578), [[AAAI 2024]](https://arxiv.org/abs/2305.10701), [[TOSEM 2021]](https://dl.acm.org/doi/10.1145/3490489), [[ISCI 2020]](https://www.sciencedirect.com/science/article/pii/S0020025520308124), [[TIP 2020]](https://arxiv.org/abs/1909.06978)
- AI Fairness: [[FSE 2025]](), [[ICSE 2025]](https://conf.researchr.org/details/icse-2025/icse-2025-research-track/216/Dissecting-Global-Search-A-Simple-yet-Effective-Method-to-Boost-Individual-Discrimin), [[ICSE 2024]](https://dl.acm.org/doi/10.1145/3597503.3623334), [[TOSEM 2023]](https://dl.acm.org/doi/10.1145/3617168), [[ICML 2023]](https://arxiv.org/abs/2306.15299), [[IJCAI 2023]](https://dl.acm.org/doi/abs/10.24963/ijcai.2023/49), [[ISSTA 2023]](https://arxiv.org/abs/2305.11602)
- Trustworthy Code Intelligence: [[TOSEM 2025]](https://arxiv.org/abs/2401.06391), [[ICSE NEIR 2025]](https://arxiv.org/abs/2410.09048), [[ASE 2024]](https://dl.acm.org/doi/10.1145/3691620.3695555), [[Coling 2024]](https://arxiv.org/abs/2201.07381), [[ASE 2023]](https://ieeexplore.ieee.org/document/10298289)
- Interpretability and Its Applications: [[TOSEM 2025]](https://arxiv.org/pdf/2407.20281v1), [[ICLR 2025]](https://arxiv.org/abs/2410.01296), [[TCAD 2024]](https://arxiv.org/abs/2404.12850), [[ICML 2024]](https://openreview.net/forum?id=JObct1zyTb), [[AAAI 2024]](https://ojs.aaai.org/index.php/AAAI/article/view/29146), [[ICLR 2020]](https://arxiv.org/abs/1908.01581)

<font color="blue">I am currently learning and working on <b>building trustworthy AI infrastructure</b>. I welcome feedback, support, and collaboration opportunities from others in the field to further refine and advance this work.</font>



# News

---
- <img src="https://ltl7155.github.io/images/new.gif">&nbsp; June 2025: I have been awarded the Chinese Government Award for Outstanding Self-Financed Students.
- <img src="https://ltl7155.github.io/images/new.gif">&nbsp; May 2025: Our paper "Defending LVLMs Against Vision Attacks through Partial-Perception Supervision" is accepted by ICML 2025.
- <img src="https://ltl7155.github.io/images/new.gif">&nbsp; April 2025: I have been selected as one of the best reviewers for AISTATS 2025.
- <img src="https://ltl7155.github.io/images/new.gif">&nbsp; April 2025: Our paper "Software Fairness Dilemma: Is Bias Mitigation a Zero-Sum Game?" is accepted by FSE 2025.
- <img src="https://ltl7155.github.io/images/new.gif">&nbsp; Mar 2025: Our paper "Compromising embodied agents with contextual backdoor attacks" is accepted by TIFS 2025.
- <img src="https://ltl7155.github.io/images/new.gif">&nbsp; Mar 2025: Our paper "NeuSemSlice: Towards Effective DNN Model Maintenance via Neuron-level Semantic Slicing" is accepted by TOSEM 2025.
- <img src="https://ltl7155.github.io/images/new.gif">&nbsp; Mar 2025: Our paper "JailGuard: A Universal Detection Framework for Prompt-based Attacks on LLM Systems" is accepted by TOSEM 2025.
- <img src="https://ltl7155.github.io/images/new.gif">&nbsp; Jan 2025: Our paper "Dormant: Defending against Pose-driven Human Image Animation" is accepted by USENIX Security 2025.
- <img src="https://ltl7155.github.io/images/new.gif">&nbsp; Jan 2025: Our paper "Speculative Coreset Selection for Task-Specific Fine-tuning" is accepted by ICLR 2025.
- <img src="https://ltl7155.github.io/images/new.gif">&nbsp; Jan 2025: Our paper "Understanding the Effectiveness of Coverage Criteria for Large Language Models: A Special Angle from Jailbreak Attacks" is accepted by ICSE 2025.
- <img src="https://ltl7155.github.io/images/new.gif">&nbsp; Jan 2025: Our paper "Dissecting Global Search: A Simple yet Effective Method to Boost Individual Discrimination Testing and Repair" is accepted by ICSE 2025.
- <img src="https://ltl7155.github.io/images/new.gif">&nbsp; Jan 2025: Our paper, "Perception-Guided Jailbreak Against Text-to-Image Models," has been selected for an oral presentation at AAAI 2025.
- <img src="https://ltl7155.github.io/images/new.gif">&nbsp; Jan 2025: Our paper "Teaching Code LLMs to Use Autocompletion Tools in Repository-Level Code Generation" is accepted by TOSEM 2025. 
- <img src="https://ltl7155.github.io/images/new.gif">&nbsp; Dec 2024: Our paper "Towards Trustworthy LLMs for Code: A Data-Centric Synergistic Auditing Framework" is accepted by ICSE 2025 NIER track. 
- <img src="https://ltl7155.github.io/images/new.gif">&nbsp; Dec 2024: Our paper "Perception-guided jailbreak against text-to-image models" is accepted by AAAI 2025. 
- <img src="https://ltl7155.github.io/images/new.gif">&nbsp; Nov 2024: I have been selected as one of the top reviewers for NeurIPS 2024 (1304/15160 8.6%).
- <img src="https://ltl7155.github.io/images/new.gif">&nbsp; Nov 2024: We won the championship in the NTU 2024 Staff 3x3 Basketball Tournament and achieved 1st runner-up in the 2024 Sports Challenge Basketball Event.
- <img src="https://ltl7155.github.io/images/new.gif">&nbsp; Oct 2024: Our paper "BDefects4NN: A Backdoor Defect Database for Controlled Localization Studies in Neural Networks" is accepted by ICSE 2025. Congrats to Yisong!
- <img src="https://ltl7155.github.io/images/new.gif">&nbsp; Sept 2024: Our paper "SampDetox: Black-box Backdoor Defense via Perturbation-based Sample Detoxification" is accepted by NeurIPS 2024.
- <img src="https://ltl7155.github.io/images/new.gif">&nbsp; Aug 2024: Our paper "VulAdvisor: Natural Language Suggestion Generation for Software Vulnerability Repair" is accepted by ASE 2024.
- <img src="https://ltl7155.github.io/images/new.gif">&nbsp; July 2024: Our paper "CaBaFL: Asynchronous Federated Learning via Hierarchical Cache and Feature Balance" is accepted by EMSOFT 2024 and TCAD.
- <img src="https://ltl7155.github.io/images/new.gif">&nbsp; May 2024: Our paper "Improving Neural Logic Machines via Failure Reflection" is accepted by ICML 2024. Congrats to Zhiming!
- <img src="https://ltl7155.github.io/images/new.gif">&nbsp; April 2024: I get the DAAD AInet Fellowship.
- <img src="https://ltl7155.github.io/images/new.gif">&nbsp; Feb 2024: Our paper "Unveiling project-specific bias in neural code models" is accepted by COLING 2024.
- <img src="https://ltl7155.github.io/images/new.gif">&nbsp; Feb 2024: Our paper "BadEdit: Backdooring Large Language Models by Model Editing" is accepted by ICLR 2024.
- <img src="https://ltl7155.github.io/images/new.gif">&nbsp; Feb 2024: Our paper "IRAD: Implicit Representation-driven Image Resampling against Adversarial Attacks" is accepted by ICLR 2024.
- <img src="https://ltl7155.github.io/images/new.gif">&nbsp; Dec 2023: Our paper "FedMut: Generalized Federated Learning via Stochastic Mutation" is accepted by AAAI 2024 <font color="blue">(oral)</font>.
- <img src="https://ltl7155.github.io/images/new.gif">&nbsp; Dec 2023: Our paper "Personalization as a Shortcut for Few-Shot Backdoor Attack against Text-to-Image Diffusion Model" is accepted by AAAI 2024.

---

<div class="footer" style="padding-left: 6px; font-weight: bold; color: #000000; text-align: center; font-size: 1.5em;">
  <table align="center" style="height: 100px; width: 100px;">
        <!--
         style="display: none"
         //www.clustrmaps.com/map_v2.png?d=c0iE23T-kE1Z77RydQ1UoeK1VAiMMSYMmQ2R2rgt6Mk&cl=ffffff
        -->
        <tr>
                <th align="center">
                <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=kLhn--rwfJURcjclnBM3joupiZ77SHZ341PxzqX02uI"></script>
                <!--script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=qd22-Wpe7CUKe3FdY6eqGMd4TnBY6bmR9XIIyxh0TII&cl=ffffff&w=a"></script-->
                </th>
        </tr>
  </table>
</div>

---
